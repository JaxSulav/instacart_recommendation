{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Use sql JOIN to get desired columns\n",
    "\n",
    "```sql\n",
    "    SELECT p.product_id, o.order_dow, o.user_id, op.add_to_cart_order FROM products p JOIN order_products op ON p.product_id = op.product_id JOIN orders o ON op.order_id = o.order_id;\n",
    "```\n",
    "### Ran in in terminal to create csv file for required columns:\n",
    "\n",
    "```sql\n",
    "    mysql -u root -p warehouse2 -e \"SELECT p.product_id, o.order_dow, o.user_id, op.add_to_cart_order FROM products p JOIN order_products op ON p.product_id = op.product_id JOIN orders o ON op.order_id = o.order_id INTO OUTFILE '~/resultgg.csv' FIELDS TERMINATED BY ',' ENCLOSED BY '\\\"' LINES TERMINATED BY '\\n';\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since, we forgot to put the column names while joining the tables, let's do that now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>user_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cool Mint Chocolate Energy Bar</td>\n",
       "      <td>5531</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Healthy Grains Granola Bar, Vanilla Blueberry</td>\n",
       "      <td>1545</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peach-Pear Sparkling Water</td>\n",
       "      <td>1831</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total 2% Lowfat Greek Strained Yogurt With Blu...</td>\n",
       "      <td>4957</td>\n",
       "      <td>2</td>\n",
       "      <td>451</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Organic Cream Of Chicken Condensed Soup</td>\n",
       "      <td>5499</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  product_id  order_dow  \\\n",
       "0                     Cool Mint Chocolate Energy Bar        5531          3   \n",
       "1      Healthy Grains Granola Bar, Vanilla Blueberry        1545          3   \n",
       "2                         Peach-Pear Sparkling Water        1831          3   \n",
       "3  Total 2% Lowfat Greek Strained Yogurt With Blu...        4957          2   \n",
       "4            Organic Cream Of Chicken Condensed Soup        5499          0   \n",
       "\n",
       "   user_id  add_to_cart_order  \n",
       "0       90                 10  \n",
       "1       90                  7  \n",
       "2       90                  4  \n",
       "3      451                  3  \n",
       "4      503                  1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/final_gg.csv', names=['product_name', 'product_id', 'order_dow', 'user_id', 'add_to_cart_order'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Banana Buyers\n",
    "- Get the top 5 user_ids from users who frequently buy bananas\n",
    "- Case match is false\n",
    "- Handled edge case of finding both bananas and banana in product name\n",
    "- [62443, 69919, 151361, 120232, 194931] These are the top users according to dataset, just putting here for reference so that we can compare later or unit test it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324645, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[62443, 69919, 151361, 120232, 194931]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_atc = df[df['add_to_cart_order'] < 5]\n",
    "bananas_df = df_atc[df_atc['product_name'].str.contains(\"Bananas|Banana\", case=False)]\n",
    "print(bananas_df.shape)\n",
    "top_banana_buyers = bananas_df['user_id'].value_counts().index.tolist()[:5]\n",
    "\n",
    "top_banana_buyers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The ratings are used in collaborative filtering as if two people like the same thing once, they are likely to have similar taste for other items as well. Well, in our case, we have add_to_cart_order. means how much they like them.\n",
    "\n",
    "> Ratings are also used in matrix factorization as the matrix cells values determining which user liked which product how much?\n",
    "\n",
    "##### Since, ratings are the building blocks for collaborative filtering and matrix factorization, and we do NOT have rating values, we will use \"add_to_cart_order\" as the rating. It makes sense because how many time user has added a product in cart ideally leads to how much they like them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise Prep \n",
    "reader = Reader(rating_scale=(1, df_atc['add_to_cart_order'].max()))\n",
    "data = Dataset.load_from_df(df_atc[['user_id', 'product_id', 'add_to_cart_order']], reader)\n",
    "\n",
    "# Train Prep\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "model = SVD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since, we need to consider strong and weak generalizations, let's prepare those now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We know that strong generalizations are just the testing sets, but the weak generalization are any items that are in the training set. So, for weak generalization we will take 1000 random entries from the data and then use **(the user and user_dow combination)** to generate a weak generalized testing set\n",
    "\n",
    "> order_dow is the order day of week, 0=Monday, 1=Tuesday so on... (at least this is our assumption here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7240\n"
     ]
    }
   ],
   "source": [
    "df_user_dow_uniques = df_atc[['user_id', 'order_dow']].drop_duplicates()\n",
    "# df_user_dow_randoms = df_user_dow_uniques.sample(1000, random_state=42, replace=False)\n",
    "df_user_dow_randoms = df_user_dow_uniques.sample(1000, replace=False) # Using replace to delete the value after taking it, to ensure uniqueness\n",
    "\n",
    "strong_test = list()\n",
    "for _, row in df_user_dow_randoms.iterrows():\n",
    "    user = row['user_id']\n",
    "    order_dow = row['order_dow']\n",
    "    # print(\"GG: \", row['order_dow'])\n",
    "    user_dow_products = df_atc[(df_atc['user_id'] == user) & (df_atc['order_dow'] == order_dow)]\n",
    "    # print(\"EZ: \", user_dow_products)\n",
    "    for _, product_row in user_dow_products.iterrows():\n",
    "        strong_test.append((user, product_row['product_id'], product_row['add_to_cart_order']))\n",
    "print(len(strong_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of time for the loop by using **Indexing:** Pretty fast: :) [Runtime decreased from 7.6 sec to 0.8 sec] (Tested with random_state=42)\n",
    "> We create an indexed dataset, a new data frame because the columns will be used as index and will not be available for use after we do this. So, we will stored the indexed values in new data frame. \n",
    "\n",
    "> Later we can use this to get the combination of user and user_dow :\n",
    "\n",
    "```python\n",
    "    products = indexed_df_atc.loc[(user, order_dow)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df_atc = df_atc.set_index(['user_id', 'order_dow'])\n",
    "indexed_df_atc.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7380\n"
     ]
    }
   ],
   "source": [
    "df_user_dow_uniques = df_atc[['user_id', 'order_dow']].drop_duplicates()\n",
    "# df_user_dow_randoms = df_user_dow_uniques.sample(1000, random_state=42, replace=False)\n",
    "df_user_dow_randoms = df_user_dow_uniques.sample(1000, replace=False)\n",
    "\n",
    "strong_test = list()\n",
    "for _, row in df_user_dow_randoms.iterrows():\n",
    "    user = row['user_id']\n",
    "    order_dow = row['order_dow']\n",
    "    # print(\"GG: \", row['order_dow'])\n",
    "    user_dow_products = indexed_df_atc.loc[(user, order_dow)]\n",
    "    # print(\"EZ: \", user_dow_products)\n",
    "    for _, product_row in user_dow_products.iterrows():\n",
    "        strong_test.append((user, product_row['product_id'], product_row['add_to_cart_order']))\n",
    "print(len(strong_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting in t_minus.... secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train)\n",
    "predictions = model.test(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for top 5 Banana buyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendation for user 62443: Peach,  Apricot & Banana Stage 2 Baby Food\n",
      "Top recommendation for user 69919: Plus Lotion Facial Tissues\n",
      "Top recommendation for user 151361: Organic Baby Arugula\n",
      "Top recommendation for user 120232: Organic Gala Apples\n",
      "Top recommendation for user 194931: Fat Free Milk\n"
     ]
    }
   ],
   "source": [
    "for user in top_banana_buyers:\n",
    "    df_top_buyers = df_atc[df_atc['user_id'] == user]\n",
    "    results = []\n",
    "    for _, row in df_top_buyers.iterrows():\n",
    "        pred = model.predict(user, row['product_id'])\n",
    "        results.append((row['product_name'], pred.est))\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Top recommendation for user {user}: {results[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction object from surprise contains user_id, product_id, true_atc, est_atc, details. We will take them and create a new dictionary of list of tuples where inner tuples contains the (product_id, true_atc, est_atc), then we sort it by the 3rd value of tuple which is estimated_atco. After that we can create two lists containing the actual products and the predicted products for each users in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_top_n_predictions = dict()\n",
    "\n",
    "for user_id, product_id, true_atc, est_atc, _ in predictions:\n",
    "    # Need to check if user is already in the dict key, if is not then need to create new entry for user in dict, else add predictions(product_id, true_atc, est_atc) to the same user.\n",
    "    if user_id in users_with_top_n_predictions:\n",
    "        users_with_top_n_predictions[user_id].append((product_id, true_atc, est_atc))\n",
    "    else:\n",
    "        users_with_top_n_predictions[user_id] = [(product_id, true_atc, est_atc)]\n",
    "\n",
    "# users_with_top_n_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The value of thresh is the threshold for atco, if it is greater than mean, the relevancy of the recommended product is high. So, let's put is a little bit greater than mean which is 2 (ratings being 0 to 4 as the atco < 5)\n",
    "> We will experiment with thresh later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45441, 45441, 6907, 40997, 39170], [19678, 19678, 32293, 4799, 43961, 21938, 30233, 27104, 21137, 21137, 47209, 47209, 47209, 5618, 12442, 15872, 20119, 32655], [25718, 25718, 21463, 46667, 4461, 41072, 39409, 39577, 31973, 32652, 32652, 32652, 32652, 32652, 21903, 38311, 38311, 12341, 21174, 11109, 4472, 4472, 4472], [11365, 33000, 30406], [25691, 36189, 4697, 2275], [42014, 32691], [8193, 8193, 44133, 7021, 23270, 23270, 23270, 23270, 2295, 37107, 21903, 2979, 5120, 5120, 5120, 24852, 37220]]\n",
      "[[4155, 45441, 45441, 6907, 38374], [19678, 19678, 32293, 32293, 4799], [25718, 25718, 25718, 2078, 21463], [11365, 33000, 30406, 30406, 5068], [25691, 36189, 36189, 4697, 2275], [43139, 4313, 42014, 32691], [8193, 8193, 38273, 44133, 7021]]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "thresh = 3\n",
    "actual, predicted = list(), list()\n",
    "for user_id, product_true_est in users_with_top_n_predictions.items():\n",
    "    product_true_est.sort(key=lambda x: x[2], reverse=True) # sorting by 3rd value (estimated atc) of tuple inside the list inside that dict (users_with_top_n_predictions)\n",
    "    actual.append([product_id for (product_id, true_atc, _) in product_true_est if true_atc >= thresh])\n",
    "    # Because the product_true_est object is sorted according to estimated atc(or estimated rating), we can take the top k elements for predicted\n",
    "    predicted.append([product_id for (product_id, _, _) in product_true_est[:k]])\n",
    "\n",
    "print(actual[:7])\n",
    "print(predicted[:7])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To calculate MAP@5, need to create function. GG, will do later... TODO\n",
    "#### Once the function is ready, we already have weak and strong generalizations created to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
